{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShauryaJ1/qml_tutorial/blob/main/QML_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "vfvnyqsqtTZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane qiskit qiskit_machine_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfJcFGYYtMYJ",
        "outputId": "931f6b4d-f130-4092-fb66-5b14d56f877a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-1.3.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from qiskit_machine_learning) (1.6.0)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.11/dist-packages (from qiskit_machine_learning) (75.1.0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.5.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2024.12.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-1.3.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_machine_learning-0.8.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, symengine, scipy-openblas32, rustworkx, pbr, dill, autoray, stevedore, diastatic-malt, qiskit, qiskit_machine_learning, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 diastatic-malt-2.15.2 dill-0.3.9 pbr-6.1.0 pennylane-0.40.0 pennylane-lightning-0.40.0 qiskit-1.3.2 qiskit_machine_learning-0.8.2 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 stevedore-5.4.0 symengine-0.13.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcgtZw5ftGdq"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import cat, no_grad, manual_seed\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "from torch.nn import (\n",
        "    Module,\n",
        "    Conv2d,\n",
        "    Linear,\n",
        "    Dropout2d,\n",
        "    NLLLoss,\n",
        "    MaxPool2d,\n",
        "    Flatten,\n",
        "    Sequential,\n",
        "    ReLU,\n",
        ")\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "from qiskit_machine_learning.utils import algorithm_globals\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.primitives import StatevectorEstimator as Estimator\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import torchvision\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST with Qiskit"
      ],
      "metadata": {
        "id": "d26sqX8cv77k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Dataset\n",
        "# -------------\n",
        "\n",
        "# Set train shuffle seed (for reproducibility)\n",
        "manual_seed(42)\n",
        "\n",
        "batch_size = 1\n",
        "n_samples = 100  # We will concentrate on the first 100 samples\n",
        "\n",
        "# Use pre-defined torchvision function to load MNIST train data\n",
        "X_train = datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
        "idx = np.append(\n",
        "    np.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n",
        ")\n",
        "X_train.data = X_train.data[idx]\n",
        "X_train.targets = X_train.targets[idx]\n",
        "\n",
        "# Define torch dataloader with filtered data\n",
        "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ObFGc_CdtreW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples_show = 6\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
        "\n",
        "while n_samples_show > 0:\n",
        "    images, targets = data_iter.__next__()\n",
        "\n",
        "    axes[n_samples_show - 1].imshow(images[0, 0].numpy().squeeze(), cmap=\"gray\")\n",
        "    axes[n_samples_show - 1].set_xticks([])\n",
        "    axes[n_samples_show - 1].set_yticks([])\n",
        "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets[0].item()))\n",
        "\n",
        "    n_samples_show -= 1"
      ],
      "metadata": {
        "id": "c_U9M02qtynG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 50\n",
        "\n",
        "# Use pre-defined torchvision function to load MNIST test data\n",
        "X_test = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
        "idx = np.append(\n",
        "    np.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n",
        ")\n",
        "X_test.data = X_test.data[idx]\n",
        "X_test.targets = X_test.targets[idx]\n",
        "\n",
        "# Define torch dataloader with filtered data\n",
        "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "gaZ6Rhtwt7nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = Estimator()\n",
        "def create_qnn():\n",
        "    feature_map = ZZFeatureMap(2)\n",
        "    ansatz = RealAmplitudes(2, reps=1)\n",
        "    qc = QuantumCircuit(2)\n",
        "    qc.compose(feature_map, inplace=True)\n",
        "    qc.compose(ansatz, inplace=True)\n",
        "\n",
        "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
        "    qnn = EstimatorQNN(\n",
        "        circuit=qc,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=ansatz.parameters,\n",
        "        input_gradients=True,\n",
        "        estimator=estimator,\n",
        "    )\n",
        "    return qnn\n",
        "\n",
        "\n",
        "qnn4 = create_qnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRXOpM4kuAGK",
        "outputId": "3b88e69a-8c55-435f-fa8b-6a4a5efb56b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(Module):\n",
        "    def __init__(self, qnn):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
        "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
        "        self.dropout = Dropout2d()\n",
        "        self.fc1 = Linear(256, 64)\n",
        "        self.fc2 = Linear(64, 2)  # 2-dimensional input to QNN\n",
        "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
        "        # uniformly at random from interval [-1,1].\n",
        "        self.fc3 = Linear(1, 1)  # 1-dimensional output from QNN\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.qnn(x)  # apply QNN\n",
        "        x = self.fc3(x)\n",
        "        return cat((x, 1 - x), -1)\n",
        "\n",
        "\n",
        "model4 = Net(qnn4)"
      ],
      "metadata": {
        "id": "3-mTmsBIuHA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
        "loss_func = NLLLoss()\n",
        "\n",
        "# Start training\n",
        "epochs = 10  # Set number of epochs\n",
        "loss_list = []  # Store loss history\n",
        "model4.train()  # Set model to training mode\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
        "        output = model4(data)  # Forward pass\n",
        "        loss = loss_func(output, target)  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Optimize weights\n",
        "        total_loss.append(loss.item())  # Store loss\n",
        "    loss_list.append(sum(total_loss) / len(total_loss))\n",
        "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
      ],
      "metadata": {
        "id": "0TEE7hHwvP4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model4.state_dict(), \"model4.pt\")\n"
      ],
      "metadata": {
        "id": "9JyZGPhsvSci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qnn5 = create_qnn()\n",
        "model5 = Net(qnn5)\n",
        "model5.load_state_dict(torch.load(\"model4.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2zZY9nlvVOJ",
        "outputId": "2c602acc-6484-45a6-8928-728052e5ee18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n",
            "<ipython-input-36-38593a94e951>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model5.load_state_dict(torch.load(\"model4.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.eval()  # set model to evaluation mode\n",
        "with no_grad():\n",
        "\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        output = model5(data)\n",
        "        if len(output.shape) == 1:\n",
        "            output = output.reshape(1, *output.shape)\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        loss = loss_func(output, target)\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "    print(\n",
        "        \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
        "            sum(total_loss) / len(total_loss), correct / len(test_loader) / batch_size * 100\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "zx9P9DbgveQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples_show = 6\n",
        "count = 0\n",
        "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
        "\n",
        "model5.eval()\n",
        "with no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if count == n_samples_show:\n",
        "            break\n",
        "        output = model5(data[0:1])\n",
        "        if len(output.shape) == 1:\n",
        "            output = output.reshape(1, *output.shape)\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "        axes[count].imshow(data[0].numpy().squeeze(), cmap=\"gray\")\n",
        "\n",
        "        axes[count].set_xticks([])\n",
        "        axes[count].set_yticks([])\n",
        "        axes[count].set_title(\"Predicted {}\".format(pred.item()))\n",
        "\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "TU9wSDBpvhgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PennyLane Quantum Transfer Learning with ResNet18\n"
      ],
      "metadata": {
        "id": "0YxAX88ZwtLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://download.pytorch.org/tutorial/hymenoptera_data.zip"
      ],
      "metadata": {
        "id": "qANd-Nz97_a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/hymenoptera_data.zip -d /content/"
      ],
      "metadata": {
        "id": "LAim1cIk3_Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 4                # Number of qubits\n",
        "step = 0.0004               # Learning rate\n",
        "batch_size = 4              # Number of samples for each training step\n",
        "num_epochs = 10           # Number of training epochs\n",
        "q_depth = 6                 # Depth of the quantum circuit (number of variational layers)\n",
        "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
        "q_delta = 0.01              # Initial spread of random quantum weights\n",
        "start_time = time.time()    # Start of the computation timer"
      ],
      "metadata": {
        "id": "T2o8GxTzvnDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"default.qubit\", wires=n_qubits)"
      ],
      "metadata": {
        "id": "b1puYpRdzgLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lRi12z7fzi3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    \"train\": transforms.Compose(\n",
        "        [\n",
        "            # transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n",
        "            # transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            # Normalize input channels using mean values and standard deviations of ImageNet.\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    ),\n",
        "    \"val\": transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    ),\n",
        "}\n",
        "\n",
        "data_dir = \"/content/hymenoptera_data\"\n",
        "image_datasets = {\n",
        "    x if x == \"train\" else \"validation\": datasets.ImageFolder(\n",
        "        os.path.join(data_dir, x), data_transforms[x]\n",
        "    )\n",
        "    for x in [\"train\", \"val\"]\n",
        "}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"validation\"]}\n",
        "class_names = image_datasets[\"train\"].classes\n",
        "\n",
        "# Initialize dataloader\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
        "    for x in [\"train\", \"validation\"]\n",
        "}\n",
        "\n",
        "# function to plot images\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Display image from tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    # Inverse of the initial normalization operation.\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ],
      "metadata": {
        "id": "6SOS_xgnztZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders[\"validation\"]))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
        "    for x in [\"train\", \"validation\"]\n",
        "}"
      ],
      "metadata": {
        "id": "ZS_9R7QOztCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders[\"validation\"]))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
        "    for x in [\"train\", \"validation\"]\n",
        "}"
      ],
      "metadata": {
        "id": "QzmePf0c0E4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def H_layer(nqubits):\n",
        "    \"\"\"Layer of single-qubit Hadamard gates.\n",
        "    \"\"\"\n",
        "    for idx in range(nqubits):\n",
        "        qml.Hadamard(wires=idx)\n",
        "\n",
        "\n",
        "def RY_layer(w):\n",
        "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
        "    \"\"\"\n",
        "    for idx, element in enumerate(w):\n",
        "        qml.RY(element, wires=idx)\n",
        "\n",
        "\n",
        "def entangling_layer(nqubits):\n",
        "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
        "    \"\"\"\n",
        "    # In other words it should apply something like :\n",
        "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
        "    #   CNOT  CNOT  CNOT...  CNOT\n",
        "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
        "        qml.CNOT(wires=[i, i + 1])"
      ],
      "metadata": {
        "id": "M6o_O-Nt0LyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev)\n",
        "def quantum_net(q_input_features, q_weights_flat):\n",
        "    \"\"\"\n",
        "    The variational quantum circuit.\n",
        "    \"\"\"\n",
        "\n",
        "    # Reshape weights\n",
        "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
        "\n",
        "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
        "    H_layer(n_qubits)\n",
        "\n",
        "    # Embed features in the quantum node\n",
        "    RY_layer(q_input_features)\n",
        "\n",
        "    # Sequence of trainable variational layers\n",
        "    for k in range(q_depth):\n",
        "        entangling_layer(n_qubits)\n",
        "        RY_layer(q_weights[k])\n",
        "\n",
        "    # Expectation values in the Z basis\n",
        "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
        "    return tuple(exp_vals)"
      ],
      "metadata": {
        "id": "nBXD_IOG0To2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drawer = qml.draw(quantum_net)\n",
        "print(drawer([0,0,0,0],np.array([0,0,0,0]*6)))\n"
      ],
      "metadata": {
        "id": "bZcMIH8G270P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DressedQuantumNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Torch module implementing the *dressed* quantum net.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Definition of the *dressed* layout.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.pre_net = nn.Linear(512, n_qubits)\n",
        "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
        "        self.post_net = nn.Linear(n_qubits, 2)\n",
        "\n",
        "    def forward(self, input_features):\n",
        "        \"\"\"\n",
        "        Defining how tensors are supposed to move through the *dressed* quantum\n",
        "        net.\n",
        "        \"\"\"\n",
        "\n",
        "        # obtain the input features for the quantum circuit\n",
        "        # by reducing the feature dimension from 512 to 4\n",
        "        pre_out = self.pre_net(input_features)\n",
        "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
        "\n",
        "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
        "        q_out = torch.Tensor(0, n_qubits)\n",
        "        q_out = q_out.to(device)\n",
        "        for elem in q_in:\n",
        "            q_out_elem = torch.hstack(quantum_net(elem, self.q_params)).float().unsqueeze(0)\n",
        "            q_out = torch.cat((q_out, q_out_elem))\n",
        "\n",
        "        # return the two-dimensional prediction from the postprocessing layer\n",
        "        return self.post_net(q_out)"
      ],
      "metadata": {
        "id": "GDV6JwRi0azi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
        "model_hybrid = torchvision.models.resnet18(weights=weights)\n",
        "\n",
        "for param in model_hybrid.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "# Notice that model_hybrid.fc is the last layer of ResNet18\n",
        "model_hybrid.fc = DressedQuantumNet()\n",
        "\n",
        "# Use CUDA or CPU according to the \"device\" object.\n",
        "model_hybrid = model_hybrid.to(device)"
      ],
      "metadata": {
        "id": "5Fq1wvi_0hEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CxvTwUqy0kxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)"
      ],
      "metadata": {
        "id": "IG3dWS9S0q_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_lr_scheduler = lr_scheduler.StepLR(\n",
        "    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "r-LagEAc0s-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = 10000.0  # Large arbitrary number\n",
        "    best_acc_train = 0.0\n",
        "    best_loss_train = 10000.0  # Large arbitrary number\n",
        "    print(\"Training started:\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in [\"train\", \"validation\"]:\n",
        "            if phase == \"train\":\n",
        "                # Set model to training mode\n",
        "                model.train()\n",
        "            else:\n",
        "                # Set model to evaluate mode\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            n_batches = dataset_sizes[phase] // batch_size\n",
        "            it = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                since_batch = time.time()\n",
        "                batch_size_ = len(inputs)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Track/compute gradient and make an optimization step only when training\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Print iteration results\n",
        "                running_loss += loss.item() * batch_size_\n",
        "                batch_corrects = torch.sum(preds == labels.data).item()\n",
        "                running_corrects += batch_corrects\n",
        "                print(\n",
        "                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
        "                        phase,\n",
        "                        epoch + 1,\n",
        "                        num_epochs,\n",
        "                        it + 1,\n",
        "                        n_batches + 1,\n",
        "                        time.time() - since_batch,\n",
        "                    ),\n",
        "                    end=\"\\r\",\n",
        "                    flush=True,\n",
        "                )\n",
        "                it += 1\n",
        "\n",
        "            # Print epoch results\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "            print(\n",
        "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
        "                    \"train\" if phase == \"train\" else \"validation  \",\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    epoch_loss,\n",
        "                    epoch_acc,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Check if this is the best model wrt previous epochs\n",
        "            if phase == \"validation\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == \"validation\" and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
        "                best_acc_train = epoch_acc\n",
        "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
        "                best_loss_train = epoch_loss\n",
        "\n",
        "            # Update learning rate\n",
        "            if phase == \"train\":\n",
        "                scheduler.step()\n",
        "\n",
        "    # Print final results\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\n",
        "        \"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
        "    )\n",
        "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
        "    return model"
      ],
      "metadata": {
        "id": "OiFREr240036"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_hybrid = train_model(\n",
        "    model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "vFZ6-d-Z4J0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6, fig_name=\"Predictions\"):\n",
        "    images_so_far = 0\n",
        "    _fig = plt.figure(fig_name)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _i, (inputs, labels) in enumerate(dataloaders[\"validation\"]):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
        "                ax.axis(\"off\")\n",
        "                ax.set_title(\"[{}]\".format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "                if images_so_far == num_images:\n",
        "                    return"
      ],
      "metadata": {
        "id": "ueKuk_pY4OIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_hybrid, num_images=batch_size)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RcN45_sM4SCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import ResNet18_Weights\n",
        "classic_model = torchvision.models.resnet18(ResNet18_Weights.IMAGENET1K_V1)\n",
        "classic_model.fc = nn.Linear(512, 2)"
      ],
      "metadata": {
        "id": "Jk25cXnU4U3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model_name,model, loaders, optimizer, criterion, device, scheduler, num_epochs, dataset_sizes, num_classes):\n",
        "    model.to(device)\n",
        "    since = time.time()\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Initialize arrays to track true positives and total counts for each class\n",
        "            true_positives = torch.zeros(num_classes).to(device)\n",
        "            total_counts = torch.zeros(num_classes).to(device)\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batch in tqdm(loaders[phase], desc=f\"{phase.capitalize()} Phase Progress\"):\n",
        "                inputs, labels = batch\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # print(inputs.device,labels.device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    # print(outputs.logits.shape)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # Update true positives and total counts for each class\n",
        "                for class_idx in range(num_classes):\n",
        "                    true_positives[class_idx] += torch.sum((preds == class_idx) & (labels == class_idx))\n",
        "                    total_counts[class_idx] += torch.sum(labels == class_idx)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate epoch loss and accuracy\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            if phase==\"test\":\n",
        "              if epoch_acc > best_test_acc:\n",
        "                best_test_acc = epoch_acc\n",
        "                print(\"Saving model...\")\n",
        "                print(f\"Best test acc: {best_test_acc}\")\n",
        "                torch.save(model.state_dict(), f\"{epoch}_{model_name}\")\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Time elapsed: {time.time() - since}')\n",
        "\n",
        "            # Calculate and print class-wise accuracies\n",
        "            class_accuracies = (true_positives / total_counts) * 100  # Convert to percentage\n",
        "            for class_idx, class_acc in enumerate(class_accuracies):\n",
        "                print(f\"Class {class_idx} Accuracy: {class_acc:.2f}%\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n"
      ],
      "metadata": {
        "id": "QHabDewv47DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes[\"test\"] = dataset_sizes[\"validation\"]"
      ],
      "metadata": {
        "id": "3n-8sC7X5HzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFy-vmXZ5bP4",
        "outputId": "94e87527-0770-43fd-f077-3408db9ada6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 244, 'validation': 153, 'test': 153}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders[\"test\"] = dataloaders[\"validation\"]"
      ],
      "metadata": {
        "id": "uASqhZHZ5qZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classic_optimizer =optim.Adam(classic_model.parameters(),lr=step)"
      ],
      "metadata": {
        "id": "bpX1qyjN61rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(\"classic_model\",classic_model,dataloaders,classic_optimizer,criterion,torch.device(\"cpu\"),lr_scheduler.StepLR(\n",
        "    classic_optimizer, step_size=10, gamma=gamma_lr_scheduler\n",
        "),10,dataset_sizes,2)"
      ],
      "metadata": {
        "id": "5QJ3Aeo75gjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Training with a Quantum Autoencoder"
      ],
      "metadata": {
        "id": "RKup5rvVBKYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class U3Rotation(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super().__init__()\n",
        "        # Trainable parameters\n",
        "        self.theta_0 = nn.Parameter(2*torch.pi* torch.rand(1))  # Initialize randomly\n",
        "        self.phi_0= nn.Parameter(torch.pi*torch.rand(1))    # Initialize randomly\n",
        "        self.theta_1 = nn.Parameter(2*torch.pi* torch.rand(1))  # Initialize randomly\n",
        "        self.phi_1 = nn.Parameter(torch.pi*torch.rand(1))    # Initialize randomly\n",
        "        self.theta_2 = nn.Parameter(2*torch.pi* torch.rand(1))  # Initialize randomly\n",
        "        self.phi_2 = nn.Parameter(torch.pi*torch.rand(1))    # Initialize randomly\n",
        "        self.theta_3 = nn.Parameter(2*torch.pi* torch.rand(1))  # Initialize randomly\n",
        "        self.phi_3 = nn.Parameter(torch.pi*torch.rand(1))    # Initialize randomly\n",
        "        self.thetas = [self.theta_0,self.theta_1,self.theta_2,self.theta_3]\n",
        "        self.phis = [self.phi_0,self.phi_1,self.phi_2,self.phi_3]\n",
        "        self.device = device\n",
        "    def forward(self, input_vector):\n",
        "        \"\"\"\n",
        "        input_vector: A 2D vector of shape (batch_size, 16) with complex values.\n",
        "        \"\"\"\n",
        "        batch_dim = input_vector.shape[0]\n",
        "        input_vector = torch.reshape(input_vector,(input_vector.shape[0],8,2))\n",
        "        input_vector = input_vector[:,:4] + input_vector[:,4:]*1j\n",
        "        norm = torch.norm(input_vector, dim=1, keepdim=True) + 1e-8\n",
        "        input_vector = input_vector / norm\n",
        "\n",
        "        cos_theta_2_0 = torch.cos(self.theta_0 / 2)\n",
        "        sin_theta_2_0 = torch.sin(self.theta_0 / 2)\n",
        "        cos_theta_2_1 = torch.cos(self.theta_1 / 2)\n",
        "        sin_theta_2_1 = torch.sin(self.theta_1 / 2)\n",
        "        cos_theta_2_2 = torch.cos(self.theta_2 / 2)\n",
        "        sin_theta_2_2 = torch.sin(self.theta_2 / 2)\n",
        "        cos_theta_2_3 = torch.cos(self.theta_3 / 2)\n",
        "        sin_theta_2_3 = torch.sin(self.theta_3 / 2)\n",
        "\n",
        "        exp_i_phi_0 = torch.exp(1j * self.phi_0)\n",
        "        exp_i_phi_1 = torch.exp(1j * self.phi_1)\n",
        "        exp_i_phi_2 = torch.exp(1j * self.phi_2)\n",
        "        exp_i_phi_3 = torch.exp(1j * self.phi_3)\n",
        "\n",
        "        rotation_matrix_0 = torch.tensor([\n",
        "            [cos_theta_2_0,-1*sin_theta_2_0],\n",
        "            [exp_i_phi_0*sin_theta_2_0,exp_i_phi_0*cos_theta_2_0]\n",
        "        ],device = self.device)\n",
        "        rotation_matrix_1 = torch.tensor([\n",
        "            [cos_theta_2_1,-1*sin_theta_2_1],\n",
        "            [exp_i_phi_1*sin_theta_2_1,exp_i_phi_1*cos_theta_2_1]\n",
        "        ],device = self.device)\n",
        "        rotation_matrix_2 = torch.tensor([\n",
        "            [cos_theta_2_2,-1*sin_theta_2_2],\n",
        "            [exp_i_phi_2*sin_theta_2_2,exp_i_phi_2*cos_theta_2_2]\n",
        "        ],device = self.device)\n",
        "        rotation_matrix_3 = torch.tensor([\n",
        "            [cos_theta_2_3,-1*sin_theta_2_3],\n",
        "            [exp_i_phi_3*sin_theta_2_3,exp_i_phi_3*cos_theta_2_3]\n",
        "        ],device = self.device)\n",
        "\n",
        "        if input_vector.dtype != torch.complex64 and input_vector.dtype != torch.complex128:\n",
        "            input_vector = input_vector.to(torch.complex64)\n",
        "\n",
        "        tupled = tuple([torch.einsum('bij,bj->bi', torch.stack((rotation_matrix_0,rotation_matrix_1,rotation_matrix_2,rotation_matrix_3)), sv) for sv in input_vector])\n",
        "        output_vector = torch.stack(tupled)\n",
        "        output_vector *=norm\n",
        "        # print(output_vector.shape)\n",
        "        real_output = torch.reshape(output_vector.real,(batch_dim,8))\n",
        "        imag_output = torch.reshape(output_vector.imag,(batch_dim,8))\n",
        "        output_vector = torch.cat((real_output,imag_output),dim=1)\n",
        "        return output_vector\n",
        "    def return_angles(self):\n",
        "        return self.thetas,self.phis"
      ],
      "metadata": {
        "id": "Kw04NXffBQpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuple([i for i in range(9)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wffm__xUYwnR",
        "outputId": "d47e8d22-d207-4429-83b5-bcac8d7ea844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 2, 3, 4, 5, 6, 7, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rot = U3Rotation(torch.device(\"cpu\"))"
      ],
      "metadata": {
        "id": "jaWd7I0iUAax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(2,16)"
      ],
      "metadata": {
        "id": "FjQIGhFfamvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = rot(input)"
      ],
      "metadata": {
        "id": "W2LiTU_5UCZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8k5ZpUNasRm",
        "outputId": "b5c8692d-3c71-4dc0-d859-f34f266c1a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1149,  0.1742, -1.2597,  0.5258, -1.4999, -0.8797, -0.9982,  1.0927,\n",
              "         -1.2896,  0.0526, -0.5390,  0.0826,  2.1487,  1.4182, -0.2370, -0.6672],\n",
              "        [-0.9309, -0.8238, -0.3336, -1.0988,  0.8605, -0.0605, -1.9280,  2.3108,\n",
              "         -1.8872,  0.8579, -0.9389, -0.0957,  1.8503,  0.6923,  0.7441,  1.6514]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmHFIYciajkq",
        "outputId": "96b960b9-e1e3-439e-ada3-73f46c045190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2500, -0.0926, -0.3777,  0.0420,  1.9809, -0.3681, -0.5997, -0.6491,\n",
              "         -1.1010,  0.4364,  0.0485, -0.9987, -3.0392,  0.2210,  0.9312, -1.0704],\n",
              "        [-0.2322,  1.1596,  1.2659,  0.7505, -0.4377,  0.3533, -0.6290, -0.1927,\n",
              "         -2.0926,  0.2569,  0.3980, -0.1828, -1.6915,  1.1202, -1.8656, -2.8893]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2,2)\n",
        "x2 = torch.rand(2,2)\n",
        "x3 = torch.rand(2,2)\n",
        "x4 = torch.rand(2,2)\n",
        "x = torch.stack((x1,x2,x3,x4))"
      ],
      "metadata": {
        "id": "oTgYSoGzHyVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yZGCA7EPS8s",
        "outputId": "fbb18c77-6220-4497-e9f7-efef7a952536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAgX4-T5OsQn",
        "outputId": "02ac8751-ec7d-4a8e-8c53-30c6bcca6bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4099, 0.0721],\n",
              "         [0.1560, 0.4884]],\n",
              "\n",
              "        [[0.7130, 0.9966],\n",
              "         [0.4297, 0.2063]],\n",
              "\n",
              "        [[0.7581, 0.0249],\n",
              "         [0.4092, 0.9722]],\n",
              "\n",
              "        [[0.8924, 0.8152],\n",
              "         [0.9548, 0.2036]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumAutoencoder(nn.Module):\n",
        "    def __init__(self, device,input_dim):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 16),\n",
        "            U3Rotation(self.device),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "f5WnVnnBun1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicalAutoencoder(nn.Module):\n",
        "  def __init__(self, device,input_dim):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 16),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "  def forward(self,x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xGthVVg9nNvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mckXZvmevAi1",
        "outputId": "52eef789-01bd-475f-db4c-b3cbbb3553a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 15.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 303kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.57MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEdB2PuBvVm7",
        "outputId": "d03dcbf6-9443-47c7-e8d6-6b817a160f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "_U_-4jb9i0eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "2gN0JQ9dvYuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_autoencoder(model, train_dataloader,criterion, optimizer, num_epochs):\n",
        "    model.to(model.device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "            inputs, _ = batch\n",
        "            inputs = inputs.to(model.device)\n",
        "            inputs = torch.reshape(inputs,(inputs.shape[0],-1))\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, inputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "YHJs7yXhizIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randn(2,28,28)"
      ],
      "metadata": {
        "id": "T3iR21nGkK0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXKAP16_kO-j",
        "outputId": "4ee9b0e5-ba1d-4d71-b122-9727fea9e0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.reshape(img,(img.shape[0],-1)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafXPuEOkQUb",
        "outputId": "aa002109-9dac-4d8d-b0ce-8bede09ab86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_autoencoder = QuantumAutoencoder(torch.device(\"cuda:0\"),28*28)"
      ],
      "metadata": {
        "id": "d_-hGcTVjPew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_criterion = nn.MSELoss()\n",
        "autoencoder_optimizer = optim.Adam(q_autoencoder.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "-KQPEZ-IjWgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_autoencoder(q_autoencoder,train_dataloader,autoencoder_criterion,autoencoder_optimizer,10)"
      ],
      "metadata": {
        "id": "253mPyfwjdGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_dataset[1][0].flatten().unsqueeze(0).to(torch.device(\"cuda:0\"))\n",
        "with torch.no_grad():\n",
        "    outputs = q_autoencoder(x)"
      ],
      "metadata": {
        "id": "JAWlIWUJj1YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x[0].cpu().reshape(28,28))"
      ],
      "metadata": {
        "id": "b-QITkS2msra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(outputs[0].cpu().reshape(28,28))"
      ],
      "metadata": {
        "id": "AR--vhCRm6HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_autoencoder = ClassicalAutoencoder(torch.device(\"cuda:0\"),28*28)"
      ],
      "metadata": {
        "id": "u3KgIrhNm8Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_criterion = nn.MSELoss()\n",
        "c_optimizer = optim.Adam(c_autoencoder.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "aW7AKqB1nhIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_autoencoder(c_autoencoder,train_dataloader,c_criterion,c_optimizer,10)"
      ],
      "metadata": {
        "id": "JDrrQ2L5naqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_autoencoder.encoder[-1].thetas"
      ],
      "metadata": {
        "id": "3j72ApZVoIMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_autoencoder.encoder[-1].phis"
      ],
      "metadata": {
        "id": "rhMFlxinoOAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, device,input_dim, hidden_dim,num_classes):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, num_classes),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Nk9IRavYnoBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_model(model, criterion, optimizer, scheduler, num_epochs):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = 10000.0  # Large arbitrary number\n",
        "    best_acc_train = 0.0\n",
        "    best_loss_train = 10000.0  # Large arbitrary number\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(\"Training started:\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in [\"train\", \"test\"]:\n",
        "            if phase == \"train\":\n",
        "                # Set model to training mode\n",
        "                model.train()\n",
        "            else:\n",
        "                # Set model to evaluate mode\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            n_batches = dataset_sizes[phase] // batch_size\n",
        "            it = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                since_batch = time.time()\n",
        "                batch_size_ = len(inputs)\n",
        "                inputs = inputs.to(device)\n",
        "                inputs = torch.reshape(inputs,(inputs.shape[0],-1))\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Track/compute gradient and make an optimization step only when training\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Print iteration results\n",
        "                running_loss += loss.item() * batch_size_\n",
        "                batch_corrects = torch.sum(preds == labels.data).item()\n",
        "                running_corrects += batch_corrects\n",
        "                print(\n",
        "                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
        "                        phase,\n",
        "                        epoch + 1,\n",
        "                        num_epochs,\n",
        "                        it + 1,\n",
        "                        n_batches + 1,\n",
        "                        time.time() - since_batch,\n",
        "                    ),\n",
        "                    end=\"\\r\",\n",
        "                    flush=True,\n",
        "                )\n",
        "                it += 1\n",
        "\n",
        "            # Print epoch results\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "            print(\n",
        "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
        "                    \"train\" if phase == \"train\" else \"validation  \",\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    epoch_loss,\n",
        "                    epoch_acc,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Check if this is the best model wrt previous epochs\n",
        "            if phase == \"test\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == \"test\" and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
        "                best_acc_train = epoch_acc\n",
        "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
        "                best_loss_train = epoch_loss\n",
        "\n",
        "            # Update learning rate\n",
        "            if phase == \"train\":\n",
        "                scheduler.step()\n",
        "\n",
        "    # Print final results\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\n",
        "        \"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
        "    )\n",
        "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
        "    return model"
      ],
      "metadata": {
        "id": "QzepLk5Npb15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train': train_dataloader, 'test': test_dataloader}\n",
        "dataset_sizes = {'train': len(train_dataset), 'test': len(test_dataset)}"
      ],
      "metadata": {
        "id": "cNF4OeVloW_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_classifier = Classifier(torch.device(\"cuda:0\"),784,16,10)"
      ],
      "metadata": {
        "id": "SIL3Qm9FpA2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_classifier.encoder = q_autoencoder.encoder"
      ],
      "metadata": {
        "id": "hfGF_31yo3D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_optimizer = optim.Adam(hybrid_classifier.parameters(), lr=0.001)\n",
        "classifier_criterion = nn.CrossEntropyLoss()\n",
        "classifier_scheduler = lr_scheduler.StepLR(classifier_optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "Hix3JxtYpu5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_classifier_model(hybrid_classifier,classifier_criterion,classifier_optimizer,classifier_scheduler,10)"
      ],
      "metadata": {
        "id": "uWjIGpbDpUeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classic_classifier = Classifier(torch.device(\"cuda:0\"),784,16,10)\n",
        "classic_optimizer = optim.Adam(classic_classifier.parameters(), lr=0.001)\n",
        "classic_criterion = nn.CrossEntropyLoss()\n",
        "classic_lr_scheduler = lr_scheduler.StepLR(classic_optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "wWqpVMGFxbX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_classifier_model(classic_classifier,classic_criterion,classic_optimizer,classic_lr_scheduler,10)"
      ],
      "metadata": {
        "id": "c7mQ-fnLyGON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N09g-AY6yQ6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}